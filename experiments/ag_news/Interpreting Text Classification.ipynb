{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import captum\n",
    "from main import TextClassificationModel\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torch import nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from captum.attr import LimeBase, KernelShap\n",
    "from captum._utils.models.linear_model import SkLearnLasso\n",
    "import torch.nn.functional as F\n",
    "from IPython.core.display import HTML, display\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer, GradientShap\n",
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization, IntegratedGradients\n",
    "# import shap\n",
    "\n",
    "\n",
    "def num_to_text(text_nums, vocab) :\n",
    "    return [vocab.vocab.itos_[i] for i in text_nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    PATH = \"./text_classification.model\"\n",
    "    tokenizer = get_tokenizer('basic_english')\n",
    "    train_iter = AG_NEWS(split='train')\n",
    "\n",
    "    def yield_tokens(data_iter):\n",
    "        for _, text in data_iter:\n",
    "            yield tokenizer(text)\n",
    "\n",
    "    vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "    text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "    label_pipeline = lambda x: int(x) - 1\n",
    "\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def collate_batch(batch):\n",
    "        label_list, text_list, offsets = [], [], [0]\n",
    "        for (_label, _text) in batch:\n",
    "            label_list.append(label_pipeline(_label))\n",
    "            processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "            text_list.append(processed_text)\n",
    "            offsets.append(processed_text.size(0))\n",
    "        label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "        offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "        text_list = torch.cat(text_list)\n",
    "        return label_list.to(device), text_list.to(device), offsets.to(device)\n",
    "\n",
    "\n",
    "\n",
    "    train_iter = AG_NEWS(split='train')\n",
    "    num_class = len(set([label for (label, text) in train_iter]))\n",
    "    vocab_size = len(vocab)\n",
    "    emsize = 64\n",
    "    #model = TextClassificationModel(vocab_size, emsize, num_class).to(device)\n",
    "    model = torch.load(\"text_classification.model\")\n",
    "    import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train(dataloader):\n",
    "        model.train()\n",
    "        total_acc, total_count = 0, 0\n",
    "        log_interval = 500\n",
    "        start_time = time.time()\n",
    "\n",
    "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            predicted_label = model(text, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            if idx % log_interval == 0 and idx > 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                      '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                                  total_acc / total_count))\n",
    "                total_acc, total_count = 0, 0\n",
    "                start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def evaluate(dataloader):\n",
    "        model.eval()\n",
    "        total_acc, total_count = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "                #print(\"One test label : \", text.shape, offsets.shape)\n",
    "                predicted_label = model(text, offsets)\n",
    "                text_converted = num_to_text(text, vocab)\n",
    "                loss = criterion(predicted_label, label)\n",
    "                total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "                total_count += label.size(0)\n",
    "        return total_acc / total_count\n",
    "\n",
    "    # Hyperparameters\n",
    "    EPOCHS = 1  # epoch\n",
    "    LR = 5  # learning rate\n",
    "    BATCH_SIZE = 1  # batch size for training\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "    total_accu = None\n",
    "    train_iter, test_iter = AG_NEWS()\n",
    "\n",
    "    train_dataset = to_map_style_dataset(train_iter)\n",
    "\n",
    "    test_dataset = to_map_style_dataset(test_iter)\n",
    "    num_train = int(len(train_dataset) * 0.95)\n",
    "    split_train_, split_valid_ = \\\n",
    "        random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                                 shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lime Base attribution:   0%|          | 0/32000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction probability: 0.897 tensor([0.0930, 0.8970, 0.0064, 0.0037], grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lime Base attribution: 100%|██████████| 32000/32000 [01:31<00:00, 348.89it/s]\n",
      "/Users/satyapriyakrishna/opt/anaconda3/lib/python3.7/site-packages/captum/_utils/models/linear_model/train.py:292: UserWarning: Must have sklearn version 0.23.0 or higher to use sample_weight in Lasso regression.\n",
      "  \"Must have sklearn version 0.23.0 or higher to use \"\n",
      "/Users/satyapriyakrishna/opt/anaconda3/lib/python3.7/site-packages/captum/_utils/models/linear_model/train.py:333: UserWarning: Sample weight is not supported for the provided linear model! Trained model without weighting inputs. For Lasso, please upgrade sklearn to a version >= 0.23.0.\n",
      "  \"Sample weight is not supported for the provided linear model!\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0972,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "         0.0000,  0.0876, -0.0000, -0.0000, -0.0000, -0.0759,  0.0000, -0.2955,\n",
      "         0.0908, -0.0000, -0.1226, -0.0000,  0.0724,  0.0000, -0.0000,  0.6067,\n",
      "         0.0000,  0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.0000,\n",
      "        -0.0845, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,\n",
      "        -0.0000,  0.1421, -0.0000,  0.6023,  0.0000, -0.2976, -0.0000,  0.0000,\n",
      "        -0.0873,  0.0065, -0.0000,  0.0000,  0.0236, -0.0000,  0.0000, -0.0000,\n",
      "        -0.0000, -0.0788])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(255,0,0,0.31180820185485425)\">us</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">men</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">have</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">right</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">touch</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">in</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">relay</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">duel</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">against</mark> <mark style=\"background-color:rgba(0,255,0,0.2959922415225603)\">australia</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">thens</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">aug</mark> <mark style=\"background-color:rgba(255,0,0,0.27548945121422047)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">17</mark> <mark style=\"background-color:rgba(255,0,0,0.5435692190680722)\">-</mark> <mark style=\"background-color:rgba(0,255,0,0.3013629243046063)\">so</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">michael</mark> <mark style=\"background-color:rgba(255,0,0,0.3501571221704613)\">phelps</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">is</mark> <mark style=\"background-color:rgba(0,255,0,0.2690452534047237)\">not</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">going</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">to</mark> <mark style=\"background-color:rgba(0,255,0,0.7789297362433992)\">match</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">the</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">seven</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">gold</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">medals</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">won</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">by</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">mark</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">spitz</mark> <mark style=\"background-color:rgba(255,0,0,0.290698730181285)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">and</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">it</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">is</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">too</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">early</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">to</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">tell</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">if</mark> <mark style=\"background-color:rgba(0,255,0,0.37700498550316053)\">he</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">will</mark> <mark style=\"background-color:rgba(0,255,0,0.7761069959412924)\">match</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">aleksandr</mark> <mark style=\"background-color:rgba(255,0,0,0.5455352994807096)\">dityatin</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">the</mark> <mark style=\"background-color:rgba(255,0,0,0.2955386804366807)\">soviet</mark> <mark style=\"background-color:rgba(0,255,0,0.08090453142434613)\">gymnast</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">who</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">won</mark> <mark style=\"background-color:rgba(0,255,0,0.15377747962746624)\">eight</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">total</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">medals</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">in</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">1980</mark> <mark style=\"background-color:rgba(255,0,0,0.2806703767218861)\">.</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # Lime Code\n",
    "    # remove the batch dimension for the embedding-bag model\n",
    "    def forward_func(text, offsets):\n",
    "        return model(text.squeeze(0), offsets)\n",
    "\n",
    "    # encode text indices into latent representations & calculate cosine similarity\n",
    "    def exp_embedding_cosine_distance(original_inp, perturbed_inp, _, **kwargs):\n",
    "        original_emb = model.embedding(original_inp, None)\n",
    "        perturbed_emb = model.embedding(perturbed_inp, None)\n",
    "        distance = 1 - F.cosine_similarity(original_emb, perturbed_emb, dim=1)\n",
    "        return torch.exp(-1 * (distance ** 2) / 2)\n",
    "\n",
    "    # binary vector where each word is selected independently and uniformly at random\n",
    "    def bernoulli_perturb(text, **kwargs):\n",
    "        probs = torch.ones_like(text) * 0.5\n",
    "        return torch.bernoulli(probs).long()\n",
    "\n",
    "    # remove absenst token based on the intepretable representation sample\n",
    "    def interp_to_input(interp_sample, original_input, **kwargs):\n",
    "        return original_input[interp_sample.bool()].view(original_input.size(0), -1)\n",
    "\n",
    "\n",
    "    \n",
    "    lasso_lime_base = LimeBase(\n",
    "        forward_func,\n",
    "        interpretable_model=SkLearnLasso(alpha=0.08),\n",
    "        similarity_func=exp_embedding_cosine_distance,\n",
    "        perturb_func=bernoulli_perturb,\n",
    "        perturb_interpretable_space=True,\n",
    "        from_interp_rep_transform=interp_to_input,\n",
    "        to_interp_rep_transform=None\n",
    "    )\n",
    "    \n",
    "    test_label = 2  # {1: World, 2: Sports, 3: Business, 4: Sci/Tec}\n",
    "    test_line = ('US Men Have Right Touch in Relay Duel Against Australia THENS, Aug. 17 '\n",
    "                 '- So Michael Phelps is not going to match the seven gold medals won by Mark Spitz. '\n",
    "                 'And it is too early to tell if he will match Aleksandr Dityatin, '\n",
    "                 'the Soviet gymnast who won eight total medals in 1980.')\n",
    "\n",
    "    test_labels, test_text, test_offsets = collate_batch([(test_label, test_line)])\n",
    "\n",
    "    probs = F.softmax(model(test_text, test_offsets), dim=1).squeeze(0)\n",
    "    print('Prediction probability:', round(probs[test_labels[0]].item(), 4), probs)\n",
    "\n",
    "    attrs = lasso_lime_base.attribute(\n",
    "        test_text.unsqueeze(0),  # add batch dimension for Captum\n",
    "        target=test_labels,\n",
    "        additional_forward_args=(test_offsets,),\n",
    "        n_samples=32000,\n",
    "        show_progress=True\n",
    "    ).squeeze(0)\n",
    "    attrs = F.normalize(attrs, p=2.0, dim=0, eps=1e-12, out=None)\n",
    "\n",
    "    print(attrs)\n",
    "    def show_text_attr(attrs):\n",
    "        rgb = lambda x: '255,0,0' if x < 0 else '0,255,0'\n",
    "        alpha = lambda x: abs(x) ** 0.5\n",
    "        token_marks = [\n",
    "            f'<mark style=\"background-color:rgba({rgb(attr)},{alpha(attr)})\">{token}</mark>'\n",
    "            for token, attr in zip(tokenizer(test_line), attrs.tolist())\n",
    "        ]\n",
    "    \n",
    "        display(HTML('<p>' + ' '.join(token_marks) + '</p>'))\n",
    "    \n",
    "    show_text_attr(attrs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satyapriyakrishna/opt/anaconda3/lib/python3.7/site-packages/captum/attr/_models/base.py:189: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n",
      "  \"In order to make embedding layers more interpretable they will \"\n"
     ]
    }
   ],
   "source": [
    "test_label = 2  # {1: World, 2: Sports, 3: Business, 4: Sci/Tec}\n",
    "test_line = ('US Men Have Right Touch in Relay Duel Against Australia THENS, Aug. 17 '\n",
    "                 '- So Michael Phelps is not going to match the seven gold medals won by Mark Spitz. '\n",
    "                 'And it is too early to tell if he will match Aleksandr Dityatin, '\n",
    "                 'the Soviet gymnast who won eight total medals in 1980.')\n",
    "\n",
    "test_labels, test_text, test_offsets = collate_batch([(test_label, test_line)])\n",
    "\n",
    "\n",
    "interpretable_embedding = configure_interpretable_embedding_layer(model, 'embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                        token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                        position_ids=None, ref_position_ids=None):\n",
    "        input_embeddings = interpretable_embedding.indices_to_embeddings(input_ids, test_offsets)\n",
    "        ref_input_embeddings = interpretable_embedding.indices_to_embeddings(ref_input_ids, test_offsets)\n",
    "        return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satyapriyakrishna/opt/anaconda3/lib/python3.7/site-packages/captum/_utils/models/linear_model/train.py:292: UserWarning: Must have sklearn version 0.23.0 or higher to use sample_weight in Lasso regression.\n",
      "  \"Must have sklearn version 0.23.0 or higher to use \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "layer_grad_shap = KernelShap(model) \n",
    "baselines = torch.zeros(test_text.shape[0]).to(torch.int64)\n",
    "input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(test_text, baselines)\n",
    "\n",
    "   \n",
    "attribution = layer_grad_shap.attribute(input_embeddings, ref_input_embeddings,\n",
    "                                            target=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0123,  1.2972,  0.4730, -0.1684,  0.3876,  0.5670, -0.4691, -0.4729,\n",
       "          0.3510, -0.2553,  2.2656, -0.2304, -0.2541, -0.1504,  0.0196,  0.0541,\n",
       "         -1.6132,  0.3716, -0.0845, -0.1136,  0.4707, -0.4951,  0.7380, -0.2249,\n",
       "         -1.2641, -0.2667, -0.2680, -0.2820,  0.4002, -0.3239,  0.0404,  0.1696,\n",
       "          0.2374,  0.1086, -0.4270,  0.7694,  0.4425, -0.3525,  0.7189,  0.7148,\n",
       "         -1.0513, -0.5707,  0.6970, -0.2568,  0.0979, -0.1607, -0.0972,  0.3368,\n",
       "          0.8625, -0.2194,  2.1601,  0.1669,  0.1086, -0.1429, -0.3077,  0.2106,\n",
       "          0.0404,  0.0227, -0.6609, -0.4729,  2.1292,  0.3120, -0.1139,  1.3582]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<mark style=\"background-color:rgba(255,0,0,1.006107159066216)\">us</mark>', '<mark style=\"background-color:rgba(0,255,0,1.1389625662462224)\">men</mark>', '<mark style=\"background-color:rgba(0,255,0,0.6877239469435061)\">have</mark>', '<mark style=\"background-color:rgba(255,0,0,0.4103759177386793)\">right</mark>', '<mark style=\"background-color:rgba(0,255,0,0.6225579235596883)\">touch</mark>', '<mark style=\"background-color:rgba(0,255,0,0.7529947571894896)\">in</mark>', '<mark style=\"background-color:rgba(255,0,0,0.6848868211121851)\">relay</mark>', '<mark style=\"background-color:rgba(255,0,0,0.6876618021520073)\">duel</mark>', '<mark style=\"background-color:rgba(0,255,0,0.5924409439738563)\">against</mark>', '<mark style=\"background-color:rgba(255,0,0,0.5052244111743958)\">australia</mark>', '<mark style=\"background-color:rgba(0,255,0,1.5051755626591437)\">thens</mark>', '<mark style=\"background-color:rgba(255,0,0,0.48004185700206536)\">,</mark>', '<mark style=\"background-color:rgba(255,0,0,0.5040628943823107)\">aug</mark>', '<mark style=\"background-color:rgba(255,0,0,0.38779152317781557)\">.</mark>', '<mark style=\"background-color:rgba(0,255,0,0.14017319287667215)\">17</mark>', '<mark style=\"background-color:rgba(0,255,0,0.23251730298188628)\">-</mark>', '<mark style=\"background-color:rgba(255,0,0,1.2701101538428043)\">so</mark>', '<mark style=\"background-color:rgba(0,255,0,0.6095804210583714)\">michael</mark>', '<mark style=\"background-color:rgba(255,0,0,0.2907337641492015)\">phelps</mark>', '<mark style=\"background-color:rgba(255,0,0,0.33707183239857524)\">is</mark>', '<mark style=\"background-color:rgba(0,255,0,0.6860813111767698)\">not</mark>', '<mark style=\"background-color:rgba(255,0,0,0.7036591725999213)\">going</mark>', '<mark style=\"background-color:rgba(0,255,0,0.8590947474494387)\">to</mark>', '<mark style=\"background-color:rgba(255,0,0,0.4742727930737993)\">match</mark>', '<mark style=\"background-color:rgba(255,0,0,1.1243209909017422)\">the</mark>', '<mark style=\"background-color:rgba(255,0,0,0.5164379589139249)\">seven</mark>', '<mark style=\"background-color:rgba(255,0,0,0.5176722027191325)\">gold</mark>', '<mark style=\"background-color:rgba(255,0,0,0.5310032215272125)\">medals</mark>', '<mark style=\"background-color:rgba(0,255,0,0.632617684976842)\">won</mark>', '<mark style=\"background-color:rgba(255,0,0,0.5691139220163516)\">by</mark>', '<mark style=\"background-color:rgba(0,255,0,0.2009948581267989)\">mark</mark>', '<mark style=\"background-color:rgba(0,255,0,0.41178364106626364)\">spitz</mark>', '<mark style=\"background-color:rgba(0,255,0,0.48724244050806215)\">.</mark>', '<mark style=\"background-color:rgba(0,255,0,0.3295115851281665)\">and</mark>', '<mark style=\"background-color:rgba(255,0,0,0.653419794967487)\">it</mark>', '<mark style=\"background-color:rgba(0,255,0,0.8771604025378685)\">is</mark>', '<mark style=\"background-color:rgba(0,255,0,0.6652227699759368)\">too</mark>', '<mark style=\"background-color:rgba(255,0,0,0.593680176895875)\">early</mark>', '<mark style=\"background-color:rgba(0,255,0,0.8478997228055785)\">to</mark>', '<mark style=\"background-color:rgba(0,255,0,0.8454446728051621)\">tell</mark>', '<mark style=\"background-color:rgba(255,0,0,1.025345109201859)\">if</mark>', '<mark style=\"background-color:rgba(255,0,0,0.7554664477655466)\">he</mark>', '<mark style=\"background-color:rgba(0,255,0,0.8348533159465087)\">will</mark>', '<mark style=\"background-color:rgba(255,0,0,0.506771546611957)\">match</mark>', '<mark style=\"background-color:rgba(0,255,0,0.3128218066748901)\">aleksandr</mark>', '<mark style=\"background-color:rgba(255,0,0,0.40087381375942877)\">dityatin</mark>', '<mark style=\"background-color:rgba(255,0,0,0.3116944779241631)\">,</mark>', '<mark style=\"background-color:rgba(0,255,0,0.5803842218600145)\">the</mark>', '<mark style=\"background-color:rgba(0,255,0,0.9287329830597649)\">soviet</mark>', '<mark style=\"background-color:rgba(255,0,0,0.4684014614053108)\">gymnast</mark>', '<mark style=\"background-color:rgba(0,255,0,1.469743676577061)\">who</mark>', '<mark style=\"background-color:rgba(0,255,0,0.4085382974606638)\">won</mark>', '<mark style=\"background-color:rgba(0,255,0,0.3295115851281665)\">eight</mark>', '<mark style=\"background-color:rgba(255,0,0,0.3780138380416571)\">total</mark>', '<mark style=\"background-color:rgba(255,0,0,0.5547241145124885)\">medals</mark>', '<mark style=\"background-color:rgba(0,255,0,0.4588863836345273)\">in</mark>', '<mark style=\"background-color:rgba(0,255,0,0.2009948581267989)\">1980</mark>', '<mark style=\"background-color:rgba(0,255,0,0.15049996674139662)\">.</mark>']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(255,0,0,1.006107159066216)\">us</mark> <mark style=\"background-color:rgba(0,255,0,1.1389625662462224)\">men</mark> <mark style=\"background-color:rgba(0,255,0,0.6877239469435061)\">have</mark> <mark style=\"background-color:rgba(255,0,0,0.4103759177386793)\">right</mark> <mark style=\"background-color:rgba(0,255,0,0.6225579235596883)\">touch</mark> <mark style=\"background-color:rgba(0,255,0,0.7529947571894896)\">in</mark> <mark style=\"background-color:rgba(255,0,0,0.6848868211121851)\">relay</mark> <mark style=\"background-color:rgba(255,0,0,0.6876618021520073)\">duel</mark> <mark style=\"background-color:rgba(0,255,0,0.5924409439738563)\">against</mark> <mark style=\"background-color:rgba(255,0,0,0.5052244111743958)\">australia</mark> <mark style=\"background-color:rgba(0,255,0,1.5051755626591437)\">thens</mark> <mark style=\"background-color:rgba(255,0,0,0.48004185700206536)\">,</mark> <mark style=\"background-color:rgba(255,0,0,0.5040628943823107)\">aug</mark> <mark style=\"background-color:rgba(255,0,0,0.38779152317781557)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.14017319287667215)\">17</mark> <mark style=\"background-color:rgba(0,255,0,0.23251730298188628)\">-</mark> <mark style=\"background-color:rgba(255,0,0,1.2701101538428043)\">so</mark> <mark style=\"background-color:rgba(0,255,0,0.6095804210583714)\">michael</mark> <mark style=\"background-color:rgba(255,0,0,0.2907337641492015)\">phelps</mark> <mark style=\"background-color:rgba(255,0,0,0.33707183239857524)\">is</mark> <mark style=\"background-color:rgba(0,255,0,0.6860813111767698)\">not</mark> <mark style=\"background-color:rgba(255,0,0,0.7036591725999213)\">going</mark> <mark style=\"background-color:rgba(0,255,0,0.8590947474494387)\">to</mark> <mark style=\"background-color:rgba(255,0,0,0.4742727930737993)\">match</mark> <mark style=\"background-color:rgba(255,0,0,1.1243209909017422)\">the</mark> <mark style=\"background-color:rgba(255,0,0,0.5164379589139249)\">seven</mark> <mark style=\"background-color:rgba(255,0,0,0.5176722027191325)\">gold</mark> <mark style=\"background-color:rgba(255,0,0,0.5310032215272125)\">medals</mark> <mark style=\"background-color:rgba(0,255,0,0.632617684976842)\">won</mark> <mark style=\"background-color:rgba(255,0,0,0.5691139220163516)\">by</mark> <mark style=\"background-color:rgba(0,255,0,0.2009948581267989)\">mark</mark> <mark style=\"background-color:rgba(0,255,0,0.41178364106626364)\">spitz</mark> <mark style=\"background-color:rgba(0,255,0,0.48724244050806215)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.3295115851281665)\">and</mark> <mark style=\"background-color:rgba(255,0,0,0.653419794967487)\">it</mark> <mark style=\"background-color:rgba(0,255,0,0.8771604025378685)\">is</mark> <mark style=\"background-color:rgba(0,255,0,0.6652227699759368)\">too</mark> <mark style=\"background-color:rgba(255,0,0,0.593680176895875)\">early</mark> <mark style=\"background-color:rgba(0,255,0,0.8478997228055785)\">to</mark> <mark style=\"background-color:rgba(0,255,0,0.8454446728051621)\">tell</mark> <mark style=\"background-color:rgba(255,0,0,1.025345109201859)\">if</mark> <mark style=\"background-color:rgba(255,0,0,0.7554664477655466)\">he</mark> <mark style=\"background-color:rgba(0,255,0,0.8348533159465087)\">will</mark> <mark style=\"background-color:rgba(255,0,0,0.506771546611957)\">match</mark> <mark style=\"background-color:rgba(0,255,0,0.3128218066748901)\">aleksandr</mark> <mark style=\"background-color:rgba(255,0,0,0.40087381375942877)\">dityatin</mark> <mark style=\"background-color:rgba(255,0,0,0.3116944779241631)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.5803842218600145)\">the</mark> <mark style=\"background-color:rgba(0,255,0,0.9287329830597649)\">soviet</mark> <mark style=\"background-color:rgba(255,0,0,0.4684014614053108)\">gymnast</mark> <mark style=\"background-color:rgba(0,255,0,1.469743676577061)\">who</mark> <mark style=\"background-color:rgba(0,255,0,0.4085382974606638)\">won</mark> <mark style=\"background-color:rgba(0,255,0,0.3295115851281665)\">eight</mark> <mark style=\"background-color:rgba(255,0,0,0.3780138380416571)\">total</mark> <mark style=\"background-color:rgba(255,0,0,0.5547241145124885)\">medals</mark> <mark style=\"background-color:rgba(0,255,0,0.4588863836345273)\">in</mark> <mark style=\"background-color:rgba(0,255,0,0.2009948581267989)\">1980</mark> <mark style=\"background-color:rgba(0,255,0,0.15049996674139662)\">.</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#attribution2 = F.normalize(attribution, p=2.0, dim=0)\n",
    "\n",
    "def show_text_attr(attrs):\n",
    "        rgb = lambda x: '255,0,0' if x < 0 else '0,255,0'\n",
    "        alpha = lambda x: abs(x) ** 0.5\n",
    "        token_marks = [\n",
    "            f'<mark style=\"background-color:rgba({rgb(attr)},{alpha(attr)})\">{token}</mark>'\n",
    "            for token, attr in zip(tokenizer(test_line), attrs.tolist())\n",
    "        ]\n",
    "        print(token_marks)\n",
    "    \n",
    "        display(HTML('<p>' + ' '.join(token_marks) + '</p>'))\n",
    "    \n",
    "show_text_attr(attribution.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('we', -1.9076507091522217)\n",
      "('talk', 0.6008592844009399)\n",
      "('about', 0.8334792852401733)\n",
      "('sports', -0.34259605407714844)\n"
     ]
    }
   ],
   "source": [
    "for i in zip(tokenizer(test_line), attribution.squeeze(0).tolist()):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9077,  0.6009,  0.8335, -0.3426,  0.1981,  0.7604, -0.6456,  0.6146,\n",
       "          0.2343,  0.0832,  0.7104,  0.1022, -0.7301,  0.4617,  0.8813, -0.1982,\n",
       "          0.4625,  0.2343,  5.7208,  0.3786,  0.3361, -0.1519, -0.0339,  0.2571,\n",
       "          0.3089,  1.0197, -0.3654,  0.1447,  0.8239,  0.4731, -0.2086,  0.5020,\n",
       "         -0.0367, -0.1019,  0.2885,  0.0327,  0.7253,  0.3786,  2.2384,  0.0968,\n",
       "          0.3095,  0.7376,  0.6863, -0.9640,  0.5611,  0.1504, -0.2511,  0.2455,\n",
       "          0.5627,  0.7795,  0.7376,  0.4433, -0.0506, -0.0910,  1.3215,  0.3361,\n",
       "          0.7376, -0.3436, -0.2265,  0.3786,  0.3843,  0.9029,  0.8754, -0.1075]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                        token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                        position_ids=None, ref_position_ids=None):\n",
    "        input_embeddings = interpretable_embedding.indices_to_embeddings(input_ids, test_offsets)\n",
    "        ref_input_embeddings = interpretable_embedding.indices_to_embeddings(ref_input_ids, test_offsets)\n",
    "        return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_y/l72y9n0x101fp28hkc4xf_pr0000gp/T/ipykernel_52615/21236260.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mpred_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0minterpretable_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigure_interpretable_embedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpret_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_offsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_ind\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpretable_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpretable_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/_y/l72y9n0x101fp28hkc4xf_pr0000gp/T/ipykernel_52615/21236260.py\u001b[0m in \u001b[0;36minterpret_sentence\u001b[0;34m(model, test_text, test_offsets, test_labels, pred, pred_ind, min_len, interpretable_embedding, label)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# compute attributions and approximation delta using layer integrated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIntegratedGradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         attributions_ig = ig.attribute(input_embeddings, ref_input_embeddings, #additional_forward_args=(test_offsets,),\\\n\u001b[0m\u001b[1;32m     21\u001b[0m                                                n_steps=500, return_convergence_delta=True, target=test_labels)\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattributions_ig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    284\u001b[0m             )\n\u001b[1;32m    285\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             attributions = self._attribute(\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mbaselines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaselines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36m_attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         grads = self.gradient_func(\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mforward_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaled_features_tpl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# runs forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         assert outputs[0].numel() == 1, (\n\u001b[1;32m    114\u001b[0m             \u001b[0;34m\"Target not provided when necessary, cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0madditional_forward_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_additional_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m     output = forward_func(\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madditional_forward_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/phd_codes/mission_phd_daily_additions/research_codes/text_classification_v2/main.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text, offsets)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0membed2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients, TokenReferenceBase, visualization\n",
    "\n",
    "token_reference = TokenReferenceBase(reference_token_idx=0)\n",
    "vis_data_records_ig = []\n",
    "\n",
    "\n",
    "\n",
    "def interpret_sentence(model, test_text, test_offsets, test_labels,  pred, pred_ind, min_len=7, interpretable_embedding = None, label=0):\n",
    "        model.zero_grad()\n",
    "        # input_indices dim: [sequence_length]\n",
    "        seq_length = test_text.shape[0]\n",
    "        # predic\n",
    "\n",
    "        # generate reference indices for each sample\n",
    "        \n",
    "        reference_indices = token_reference.generate_reference(seq_length, device=device)\n",
    "        input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(test_text, reference_indices, test_offsets, interpretable_embedding)\n",
    "        # compute attributions and approximation delta using layer integrated gradients\n",
    "        ig = IntegratedGradients(model)\n",
    "        attributions_ig = ig.attribute(input_embeddings, ref_input_embeddings, #additional_forward_args=(test_offsets,),\\\n",
    "                                               n_steps=500, return_convergence_delta=True, target=test_labels)\n",
    "        return attributions_ig\n",
    "    #     add_attributions_to_visualizer(attributions_ig, test_text, pred, pred_ind, label, vis_data_records_ig)\n",
    "    #\n",
    "    #\n",
    "    # def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, vis_data_records):\n",
    "    #     attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    #     attributions = attributions / torch.norm(attributions)\n",
    "    #     attributions = attributions.cpu().detach().numpy()\n",
    "    #\n",
    "    #     # storing couple samples in an array for visualization purposes\n",
    "    #     vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "    #         attributions,\n",
    "    #         pred,\n",
    "    #         attributions.sum(),\n",
    "    #         text))\n",
    "\n",
    "model = torch.load(\"text_classification.model\")\n",
    "test_label = 2  # {1: World, 2: Sports, 3: Business, 4: Sci/Tec}\n",
    "test_line = ('We talk about sports')\n",
    "test_labels, test_text, test_offsets = collate_batch([(test_label, test_line)])\n",
    "pred = F.softmax(model(test_text, test_offsets), dim=1)\n",
    "pred_ind = torch.round(pred)\n",
    "interpretable_embedding = configure_interpretable_embedding_layer(model, 'embedding')\n",
    "attrs = interpret_sentence(model, test_text, test_offsets, test_labels,  pred,pred_ind,  label=2, interpretable_embedding=interpretable_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,0.9136381807142401)\">we</mark> <mark style=\"background-color:rgba(255,0,0,0.5191970921237206)\">talk</mark> <mark style=\"background-color:rgba(0,255,0,1.3741056244268235)\">about</mark> <mark style=\"background-color:rgba(255,0,0,0.5853173813866533)\">sports</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attrs = attrs[0]\n",
    "show_text_attr(attrs.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.5102e-01,  4.0210e-02,  1.1089e+00, -4.2984e-01, -2.9637e-01,\n",
       "           5.4363e-01,  2.4149e-03,  2.4999e-01,  2.0240e+00,  3.4554e-01,\n",
       "           7.5385e-01, -4.6866e-01,  3.8687e-01,  5.0212e-01,  9.8996e-01,\n",
       "          -2.7457e-01,  3.1099e-01, -1.0682e-02,  2.8944e+00,  2.2775e-04,\n",
       "          -9.0748e-01,  4.7193e-01,  1.2137e+00, -1.7071e+00, -2.1126e-01,\n",
       "           1.0765e+00, -8.3939e-02, -5.1048e-01, -3.8243e-01, -1.3251e+00,\n",
       "          -3.7028e-01,  2.6928e+00, -1.4850e-01, -8.1190e-01, -1.8261e-01,\n",
       "          -4.5970e-02, -1.7341e-02, -2.2869e-02,  6.8485e-01, -1.9277e-02,\n",
       "          -3.7351e-01,  3.2794e-01, -5.3542e-01, -1.2330e+00,  6.0880e-01,\n",
       "           4.3693e-01, -8.8090e-01,  2.1899e-02,  1.3545e+00, -1.1141e-01,\n",
       "           1.2586e+00, -6.1608e-01, -1.5722e-01, -9.5145e-03, -1.7878e-01,\n",
       "          -5.2722e-01, -1.2834e-01,  2.3180e-01, -5.3157e-01,  5.7616e-01,\n",
       "          -1.7502e+00, -1.7291e+00,  7.6840e-02, -1.4986e-01]],\n",
       "        dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor([1.2268e-06], dtype=torch.float64))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_indices = token_reference.generate_reference(30, device = 'cpu').unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2379,  0.8794, -0.2978, -0.4298,  0.1009, -0.0480,  0.4133,  0.4213,\n",
       "          2.0240, -0.1612,  0.3858, -0.4868, -0.2254,  0.8605,  0.9900, -0.2248,\n",
       "          0.7363,  0.0640,  0.9061,  0.4915, -0.1679, -0.9358,  0.6868, -0.7764,\n",
       "         -0.2968,  0.0337, -0.0742,  0.2649, -0.6827,  0.0084,  0.1198,  0.6426,\n",
       "         -0.4876, -0.8119, -0.8248,  0.3090, -0.2078, -0.1020,  0.6513,  0.0124,\n",
       "          0.3199, -0.2214, -0.7981, -0.4747,  0.4360,  0.2398,  0.0172,  0.2905,\n",
       "          0.7160, -0.1704,  0.8771,  0.1892,  0.0333,  0.2531,  0.1302,  0.2241,\n",
       "          0.3600,  0.3199,  0.0842, -0.3762, -0.5210, -0.3472, -0.3215, -0.3837]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribution == attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.3473e-01, -2.6957e-01,  1.8882e+00, -3.4260e-01, -1.6242e-01,\n",
       "         -1.5000e-01, -4.2731e-03,  2.7737e-01,  3.0920e+00,  6.0682e-01,\n",
       "          5.3031e-01, -4.5921e-01,  3.4753e-01,  4.6166e-01,  1.6990e+00,\n",
       "         -1.9817e-01,  2.9082e-01,  8.8086e-03,  5.7208e+00,  5.0812e-05,\n",
       "         -4.1451e-01,  6.2801e-01,  1.0184e-01, -9.8312e-01, -2.7794e-01,\n",
       "          1.9893e+00, -1.3318e-01, -4.0041e-01,  5.7171e-01,  1.7516e-01,\n",
       "         -2.8365e-01,  4.0791e+00, -3.6710e-02,  4.1080e-04, -1.5838e-01,\n",
       "         -3.2150e-01, -7.4263e-03, -1.0595e-02,  6.6097e-01, -4.4583e-02,\n",
       "         -2.8630e-01, -3.1165e-02,  3.7180e-02, -5.2194e-01,  8.1334e-01,\n",
       "          7.4355e-01,  1.4040e-01,  2.5691e-01,  1.5124e+00, -5.7763e-02,\n",
       "          4.5929e+00, -9.9076e-01, -5.0612e-02, -1.9402e-03,  1.5653e-01,\n",
       "         -7.2541e-01,  9.4780e-02,  4.1349e-01, -6.0663e-01,  6.4594e-01,\n",
       "         -1.0336e+00, -1.0643e+00,  7.1016e-02, -1.1892e-01]],\n",
       "       dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
