{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e831f8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a0c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import captum\n",
    "from train_without_embedding_bag import TextClassificationModel\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torch import nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from captum.attr import LimeBase, KernelShap\n",
    "from captum._utils.models.linear_model import SkLearnLasso\n",
    "import torch.nn.functional as F\n",
    "from IPython.core.display import HTML, display\n",
    "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer, GradientShap\n",
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization, IntegratedGradients\n",
    "# import shap\n",
    "from scipy.stats.stats import pearsonr\n",
    "import itertools\n",
    "\n",
    "\n",
    "NUM_EXPLANATIONS = 3\n",
    "EXPLANATIONS = dict()\n",
    "EXPLANATION_NAMES = dict()\n",
    "pointer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5815dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_text(text_nums, vocab) :\n",
    "    return [vocab.vocab.itos_[i] for i in text_nums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a96f509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train.csv: 29.5MB [00:00, 37.4MB/s]                                                                                               \n"
     ]
    }
   ],
   "source": [
    "    PATH = \"./text_classification_no_offset.model\"\n",
    "    tokenizer = get_tokenizer('basic_english')\n",
    "    train_iter = AG_NEWS(split='train')\n",
    "\n",
    "    def yield_tokens(data_iter):\n",
    "        for _, text in data_iter:\n",
    "            yield tokenizer(text)\n",
    "\n",
    "    vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "    vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "    text_pipeline = lambda x: vocab(x)\n",
    "    label_pipeline = lambda x: int(x) - 1\n",
    "\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94bb1b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def append_pads(text, max_len):\n",
    "        text.extend(['<pad>']*(max_len-len(text)))\n",
    "\n",
    "    def collate_batch(batch):\n",
    "        batch = [(i[0], tokenizer(i[1]) ) for i in batch]\n",
    "        max_len = max([len(i[1]) for i in batch])\n",
    "        label_list, text_list = [], []\n",
    "        for (_label, _text) in batch:\n",
    "            label_list.append(label_pipeline(_label))\n",
    "            append_pads(_text, max_len)\n",
    "            processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "            text_list.append(processed_text)\n",
    "        label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "        text_list = torch.stack(text_list)\n",
    "        return label_list.to(device), text_list.to(device)\n",
    "\n",
    "\n",
    "    train_iter = AG_NEWS(split='train')\n",
    "    num_class = len(set([label for (label, text) in train_iter]))\n",
    "    vocab_size = len(vocab)\n",
    "    emsize = 64\n",
    "    #model = TextClassificationModel(vocab_size, emsize, num_class).to(device)\n",
    "    model = torch.load(PATH, map_location=torch.device('cpu'))\n",
    "    import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe22737",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train(dataloader):\n",
    "        model.train()\n",
    "        total_acc, total_count = 0, 0\n",
    "        log_interval = 500\n",
    "        start_time = time.time()\n",
    "\n",
    "        for idx, (label, text) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            predicted_label = model(text)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            optimizer.step()\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            if idx % log_interval == 0 and idx > 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "                      '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                                  total_acc / total_count))\n",
    "                total_acc, total_count = 0, 0\n",
    "                start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c054ca9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test.csv: 1.86MB [00:00, 17.6MB/s]                                                                                                \n"
     ]
    }
   ],
   "source": [
    "    def evaluate(dataloader):\n",
    "        model.eval()\n",
    "        total_acc, total_count = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, (label, text) in enumerate(dataloader):\n",
    "                #print(\"One test label : \", text.shape, offsets.shape)\n",
    "                predicted_label = model(text)\n",
    "                text_converted = num_to_text(text, vocab)\n",
    "                loss = criterion(predicted_label, label)\n",
    "                total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "                total_count += label.size(0)\n",
    "        return total_acc / total_count\n",
    "\n",
    "    # Hyperparameters\n",
    "    EPOCHS = 1  # epoch\n",
    "    LR = 5  # learning rate\n",
    "    BATCH_SIZE = 1  # batch size for training\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "    total_accu = None\n",
    "    train_iter, test_iter = AG_NEWS()\n",
    "\n",
    "    train_dataset = to_map_style_dataset(train_iter)\n",
    "\n",
    "    test_dataset = to_map_style_dataset(test_iter)\n",
    "    num_train = int(len(train_dataset) * 0.95)\n",
    "    split_train_, split_valid_ = \\\n",
    "        random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
    "\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                                 shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db412f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   36,   433,    39,   479,  3535,     7,  3760,  8161,    63,   270,\n",
      "         20506,     3,  1146,     1,   782,    15,   303,   578,  2205,    21,\n",
      "            62,   664,     4,   620,     2,   472,   276,  2823,   192,    24,\n",
      "           600, 12368,     1,     8,    25,    21,   634,   258,     4,  2596,\n",
      "           156,    49,    33,   620, 59251, 44655,     3,     2,  6920,  7455,\n",
      "            75,   192,   630,  1321,  2823,     7,  8714,     1]]) tensor([[-0.5682,  3.3851, -0.5114, -1.9342]], grad_fn=<AddmmBackward>)\n",
      "Prediction probability: 0.9575 tensor([0.0184, 0.9575, 0.0194, 0.0047], grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lime Base attribution: 100%|██████████████████████████████████████████████████████████████| 32000/32000 [00:08<00:00, 3985.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(255,0,0,1.1765574684390099)\">us</mark> <mark style=\"background-color:rgba(0,255,0,0.3422183898151959)\">men</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">have</mark> <mark style=\"background-color:rgba(0,255,0,0.18449373018846257)\">right</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">touch</mark> <mark style=\"background-color:rgba(255,0,0,0.0983462040879542)\">in</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">relay</mark> <mark style=\"background-color:rgba(255,0,0,0.025146318870296076)\">duel</mark> <mark style=\"background-color:rgba(0,255,0,0.6546922314821125)\">against</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">australia</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">thens</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">aug</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">17</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">-</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">so</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">michael</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">phelps</mark> <mark style=\"background-color:rgba(255,0,0,0.4832759200997632)\">is</mark> <mark style=\"background-color:rgba(0,255,0,0.3180773252089324)\">not</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">going</mark> <mark style=\"background-color:rgba(255,0,0,0.15853311126393888)\">to</mark> <mark style=\"background-color:rgba(0,255,0,0.5825015478563822)\">match</mark> <mark style=\"background-color:rgba(0,255,0,0.3865092124075464)\">the</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">seven</mark> <mark style=\"background-color:rgba(0,255,0,0.6947387299586159)\">gold</mark> <mark style=\"background-color:rgba(0,255,0,0.09069555183620256)\">medals</mark> <mark style=\"background-color:rgba(0,255,0,0.5446251775878308)\">won</mark> <mark style=\"background-color:rgba(255,0,0,0.7730800689001127)\">by</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">mark</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">spitz</mark> <mark style=\"background-color:rgba(255,0,0,0.029747154076990127)\">.</mark> <mark style=\"background-color:rgba(255,0,0,0.33881669121735797)\">and</mark> <mark style=\"background-color:rgba(255,0,0,0.3904251922760836)\">it</mark> <mark style=\"background-color:rgba(255,0,0,0.5082973219930621)\">is</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">too</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">early</mark> <mark style=\"background-color:rgba(255,0,0,0.150246482982111)\">to</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">tell</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">if</mark> <mark style=\"background-color:rgba(0,255,0,1.20615258688249)\">he</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">will</mark> <mark style=\"background-color:rgba(0,255,0,0.5841048253593981)\">match</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">aleksandr</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">dityatin</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.40684518863087543)\">the</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">soviet</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">gymnast</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">who</mark> <mark style=\"background-color:rgba(0,255,0,0.5282579480379812)\">won</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">eight</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">total</mark> <mark style=\"background-color:rgba(0,255,0,0.06763639625144166)\">medals</mark> <mark style=\"background-color:rgba(255,0,0,0.1605112456258369)\">in</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">1980</mark> <mark style=\"background-color:rgba(255,0,0,0.11517706755330129)\">.</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # Lime Code\n",
    "    # remove the batch dimension for the embedding-bag model\n",
    "    def forward_func(text):\n",
    "        return model(text)\n",
    "\n",
    "    # encode text indices into latent representations & calculate cosine similarity\n",
    "    def exp_embedding_cosine_distance(original_inp, perturbed_inp, _, **kwargs):\n",
    "        original_emb = torch.mean(model.embedding(original_inp), dim = -2)\n",
    "        perturbed_emb = torch.mean(model.embedding(perturbed_inp), dim = -2)\n",
    "        #print(\"-->>\", original_emb.shape, perturbed_emb.shape, model.embedding(original_inp).shape)\n",
    "        distance = 1 - F.cosine_similarity(original_emb, perturbed_emb, dim=1)\n",
    "        return torch.exp(-1 * (distance ** 2) / 2)\n",
    "\n",
    "    # binary vector where each word is selected independently and uniformly at random\n",
    "    def bernoulli_perturb(text, **kwargs):\n",
    "        probs = torch.ones_like(text) * 0.5\n",
    "        return torch.bernoulli(probs).long()\n",
    "\n",
    "    # remove abscent token based on the intepretable representation sample\n",
    "    def interp_to_input(interp_sample, original_input, **kwargs):\n",
    "        return original_input[interp_sample.bool()].view(original_input.size(0), -1)\n",
    "\n",
    "\n",
    "    \n",
    "    lasso_lime_base = LimeBase(\n",
    "        forward_func,\n",
    "        interpretable_model=SkLearnLasso(alpha=0.08),\n",
    "        similarity_func=exp_embedding_cosine_distance,\n",
    "        perturb_func=bernoulli_perturb,\n",
    "        perturb_interpretable_space=True,\n",
    "        from_interp_rep_transform=interp_to_input,\n",
    "        to_interp_rep_transform=None\n",
    "    )\n",
    "    \n",
    "    test_label = 2  # {1: World, 2: Sports, 3: Business, 4: Sci/Tec}\n",
    "    test_line = ('US Men Have Right Touch in Relay Duel Against Australia THENS, Aug. 17 '\n",
    "                 '- So Michael Phelps is not going to match the seven gold medals won by Mark Spitz. '\n",
    "                 'And it is too early to tell if he will match Aleksandr Dityatin, '\n",
    "                 'the Soviet gymnast who won eight total medals in 1980.')\n",
    "\n",
    "    test_labels, test_text = collate_batch([(test_label, test_line)])\n",
    "    print(test_text, model(test_text))\n",
    "\n",
    "    probs = F.softmax(model(test_text), dim=1).squeeze(0)\n",
    "    print('Prediction probability:', round(probs[test_labels[0]].item(), 4), probs)\n",
    "\n",
    "    attrs_laso = lasso_lime_base.attribute(\n",
    "        test_text,  # add batch dimension for Captum\n",
    "        target=test_labels,\n",
    "        n_samples=32000,\n",
    "        show_progress=True\n",
    "    ).squeeze(0)\n",
    "    #attrs = F.normalize(attrs, p=2.0, dim=0, eps=1e-12, out=None)\n",
    "\n",
    "    #print(attrs)\n",
    "    def show_text_attr(attrs):\n",
    "        rgb = lambda x: '255,0,0' if x < 0 else '0,255,0'\n",
    "        alpha = lambda x: abs(x) ** 0.5\n",
    "        token_marks = [\n",
    "            f'<mark style=\"background-color:rgba({rgb(attr)},{alpha(attr)})\">{token}</mark>'\n",
    "            for token, attr in zip(tokenizer(test_line), attrs.tolist())\n",
    "        ]\n",
    "    \n",
    "        display(HTML('<p>' + ' '.join(token_marks) + '</p>'))\n",
    "    \n",
    "    \n",
    "\n",
    "show_text_attr(attrs_laso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4fa16f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPLANATIONS[pointer] = attrs_laso.detach().numpy()\n",
    "EXPLANATION_NAMES['LI'] = pointer\n",
    "pointer += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff1c2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lishloaner/miniconda3/lib/python3.9/site-packages/captum/attr/_models/base.py:188: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_label = 2  # {1: World, 2: Sports, 3: Business, 4: Sci/Tec}\n",
    "test_line = ('US Men Have Right Touch in Relay Duel Against Australia THENS, Aug. 17 '\n",
    "                 '- So Michael Phelps is not going to match the seven gold medals won by Mark Spitz. '\n",
    "                 'And it is too early to tell if he will match Aleksandr Dityatin, '\n",
    "                 'the Soviet gymnast who won eight total medals in 1980.')\n",
    "\n",
    "test_labels, test_text = collate_batch([(test_label, test_line)])\n",
    "\n",
    "\n",
    "interpretable_embedding = configure_interpretable_embedding_layer(model, 'embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4c783ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                        token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                        position_ids=None, ref_position_ids=None):\n",
    "        input_embeddings = interpretable_embedding.indices_to_embeddings(input_ids)\n",
    "        ref_input_embeddings = interpretable_embedding.indices_to_embeddings(ref_input_ids)\n",
    "        return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "432e2358",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "layer_grad_shap = KernelShap(model) \n",
    "baselines = torch.zeros(test_text.shape[0]).to(torch.int64)\n",
    "input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(test_text, baselines)\n",
    "\n",
    "# attribution = layer_grad_shap.attribute(input_embeddings, ref_input_embeddings,\n",
    "#                                             target=test_labels)   \n",
    "attribution_shap = torch.sum(layer_grad_shap.attribute(input_embeddings, ref_input_embeddings,\n",
    "                                            target=test_labels)*input_embeddings, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8452fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribution = torch.mean(attribution, dim = -1)*10000\n",
    "# attribution_summed = torch.sum(attribution, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d043f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution_shap = attribution_shap *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b08956b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPLANATIONS[pointer] = attribution_shap[0].detach().numpy()\n",
    "EXPLANATION_NAMES['SH'] = pointer\n",
    "pointer += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dc1c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attribution = F.normalize(attribution, p=2.0, dim=0, eps=1e-2, out=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c94b4544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,1.9067436579629697)\">us</mark> <mark style=\"background-color:rgba(0,255,0,0.5539064415418888)\">men</mark> <mark style=\"background-color:rgba(255,0,0,0.2830655520176275)\">have</mark> <mark style=\"background-color:rgba(0,255,0,0.7971533868744163)\">right</mark> <mark style=\"background-color:rgba(255,0,0,0.40911546080179734)\">touch</mark> <mark style=\"background-color:rgba(255,0,0,0.4318320941452087)\">in</mark> <mark style=\"background-color:rgba(255,0,0,0.8518943140159201)\">relay</mark> <mark style=\"background-color:rgba(0,255,0,0.6701192537263099)\">duel</mark> <mark style=\"background-color:rgba(0,255,0,0.9605895241991553)\">against</mark> <mark style=\"background-color:rgba(0,255,0,0.39318893134142047)\">australia</mark> <mark style=\"background-color:rgba(0,255,0,0.7646085648353582)\">thens</mark> <mark style=\"background-color:rgba(0,255,0,0.7848953269006774)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.40996330809396225)\">aug</mark> <mark style=\"background-color:rgba(255,0,0,0.5030815709959264)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.010741065790392407)\">17</mark> <mark style=\"background-color:rgba(255,0,0,1.5798830871544065)\">-</mark> <mark style=\"background-color:rgba(255,0,0,0.07945888955988949)\">so</mark> <mark style=\"background-color:rgba(0,255,0,0.38390793063673484)\">michael</mark> <mark style=\"background-color:rgba(255,0,0,0.6473750867355592)\">phelps</mark> <mark style=\"background-color:rgba(255,0,0,0.23381145596315728)\">is</mark> <mark style=\"background-color:rgba(0,255,0,0.4581874991091581)\">not</mark> <mark style=\"background-color:rgba(255,0,0,0.5695795025681565)\">going</mark> <mark style=\"background-color:rgba(0,255,0,0.27396389837136575)\">to</mark> <mark style=\"background-color:rgba(255,0,0,0.32169452116533764)\">match</mark> <mark style=\"background-color:rgba(255,0,0,0.8749956062751538)\">the</mark> <mark style=\"background-color:rgba(0,255,0,0.7022216504038656)\">seven</mark> <mark style=\"background-color:rgba(255,0,0,0.6696177423399681)\">gold</mark> <mark style=\"background-color:rgba(255,0,0,0.44939410891909504)\">medals</mark> <mark style=\"background-color:rgba(255,0,0,0.8223106390078214)\">won</mark> <mark style=\"background-color:rgba(0,255,0,0.4911344859274412)\">by</mark> <mark style=\"background-color:rgba(255,0,0,0.9373971882712239)\">mark</mark> <mark style=\"background-color:rgba(0,255,0,0.27363072788661574)\">spitz</mark> <mark style=\"background-color:rgba(0,255,0,0.28919968056321477)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.8630780977824105)\">and</mark> <mark style=\"background-color:rgba(255,0,0,0.8631198093443301)\">it</mark> <mark style=\"background-color:rgba(255,0,0,0.31656872145403414)\">is</mark> <mark style=\"background-color:rgba(255,0,0,0.17008370881383394)\">too</mark> <mark style=\"background-color:rgba(0,255,0,0.6256085770744652)\">early</mark> <mark style=\"background-color:rgba(0,255,0,0.5764105351020694)\">to</mark> <mark style=\"background-color:rgba(0,255,0,0.6449200469002094)\">tell</mark> <mark style=\"background-color:rgba(0,255,0,0.39811281925174125)\">if</mark> <mark style=\"background-color:rgba(255,0,0,0.5161871013702173)\">he</mark> <mark style=\"background-color:rgba(255,0,0,0.15556164151717694)\">will</mark> <mark style=\"background-color:rgba(255,0,0,0.5941536936429331)\">match</mark> <mark style=\"background-color:rgba(255,0,0,0.21798500766078557)\">aleksandr</mark> <mark style=\"background-color:rgba(255,0,0,0.6461860683036785)\">dityatin</mark> <mark style=\"background-color:rgba(255,0,0,0.33125478048293905)\">,</mark> <mark style=\"background-color:rgba(255,0,0,0.87974745442791)\">the</mark> <mark style=\"background-color:rgba(0,255,0,0.4536724893714577)\">soviet</mark> <mark style=\"background-color:rgba(0,255,0,0.3221202291158292)\">gymnast</mark> <mark style=\"background-color:rgba(255,0,0,0.7781771309176867)\">who</mark> <mark style=\"background-color:rgba(255,0,0,0.7131289985003026)\">won</mark> <mark style=\"background-color:rgba(0,255,0,0.2351771852292815)\">eight</mark> <mark style=\"background-color:rgba(255,0,0,0.6105136747601712)\">total</mark> <mark style=\"background-color:rgba(255,0,0,0.5362801271258681)\">medals</mark> <mark style=\"background-color:rgba(0,255,0,1.155731548887356)\">in</mark> <mark style=\"background-color:rgba(255,0,0,0.37042213700156057)\">1980</mark> <mark style=\"background-color:rgba(255,0,0,0.6039634943944773)\">.</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# attribution2 = F.normalize(attribution, p=2.0, dim=0)\n",
    "\n",
    "def show_text_attr(attrs):\n",
    "        rgb = lambda x: '255,0,0' if x < 0 else '0,255,0'\n",
    "        alpha = lambda x: abs(x) ** 0.5\n",
    "        token_marks = [\n",
    "            f'<mark style=\"background-color:rgba({rgb(attr)},{alpha(attr)})\">{token}</mark>'\n",
    "            for token, attr in zip(tokenizer(test_line), attrs.tolist())\n",
    "        ]    \n",
    "        display(HTML('<p>' + ' '.join(token_marks) + '</p>'))\n",
    "    \n",
    "show_text_attr(attribution_shap.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbfd0ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4bfc8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_whole_bert_embeddings(input_ids, ref_input_ids, \\\n",
    "                                        token_type_ids=None, ref_token_type_ids=None, \\\n",
    "                                        position_ids=None, ref_position_ids=None):\n",
    "        input_embeddings = interpretable_embedding.indices_to_embeddings(input_ids)\n",
    "        ref_input_embeddings = interpretable_embedding.indices_to_embeddings(ref_input_ids)\n",
    "        return input_embeddings, ref_input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e9f2aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lishloaner/miniconda3/lib/python3.9/site-packages/captum/attr/_models/base.py:188: UserWarning: In order to make embedding layers more interpretable they will be replaced with an interpretable embedding layer which wraps the original embedding layer and takes word embedding vectors as inputs of the forward function. This allows us to generate baselines for word embeddings and compute attributions for each embedding dimension. The original embedding layer must be set back by calling `remove_interpretable_embedding_layer` function after model interpretation is finished. \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients, TokenReferenceBase, visualization\n",
    "\n",
    "token_reference = TokenReferenceBase(reference_token_idx=0)\n",
    "vis_data_records_ig = []\n",
    "\n",
    "\n",
    "\n",
    "def interpret_sentence(model, test_text, test_labels,  pred, pred_ind, min_len=7, interpretable_embedding = None, label=0):\n",
    "        model.zero_grad()\n",
    "        # input_indices dim: [sequence_length]\n",
    "        seq_length = test_text.shape[0]\n",
    "        # predic\n",
    "\n",
    "        # generate reference indices for each sample\n",
    "        \n",
    "        reference_indices = token_reference.generate_reference(seq_length, device=device)\n",
    "        input_embeddings, ref_input_embeddings = construct_whole_bert_embeddings(test_text, reference_indices, interpretable_embedding)\n",
    "        # compute attributions and approximation delta using layer integrated gradients\n",
    "        ig = IntegratedGradients(model)\n",
    "        attributions_ig = ig.attribute(input_embeddings, ref_input_embeddings, #additional_forward_args=(test_offsets,),\\\n",
    "                                               n_steps=500, target=test_labels)\n",
    "        return attributions_ig #*input_embeddings\n",
    "\n",
    "model = torch.load(PATH)\n",
    "test_label = 2  # {1: World, 2: Sports, 3: Business, 4: Sci/Tec}\n",
    "test_line = ('US Men Have Right Touch in Relay Duel Against Australia THENS, Aug. 17 '\n",
    "                 '- So Michael Phelps is not going to match the seven gold medals won by Mark Spitz. '\n",
    "                 'And it is too early to tell if he will match Aleksandr Dityatin, '\n",
    "                 'the Soviet gymnast who won eight total medals in 1980.')\n",
    "test_labels, test_text = collate_batch([(test_label, test_line)])\n",
    "pred = F.softmax(model(test_text), dim=1)\n",
    "pred_ind = torch.round(pred)\n",
    "interpretable_embedding = configure_interpretable_embedding_layer(model, 'embedding')\n",
    "attrs_ig = interpret_sentence(model, test_text, test_labels,  pred,pred_ind,  label=2, interpretable_embedding=interpretable_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7196e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs_ig = torch.sum(attrs_ig, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e79e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPLANATIONS[pointer] = attrs_ig[0].detach().numpy()\n",
    "EXPLANATION_NAMES['IG'] = pointer\n",
    "pointer += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4b09bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(255,0,0,0.8760638564219314)\">us</mark> <mark style=\"background-color:rgba(0,255,0,0.5336764681229011)\">men</mark> <mark style=\"background-color:rgba(255,0,0,0.2004354626512908)\">have</mark> <mark style=\"background-color:rgba(0,255,0,0.4880335106933339)\">right</mark> <mark style=\"background-color:rgba(0,255,0,0.2149354728025289)\">touch</mark> <mark style=\"background-color:rgba(255,0,0,0.31660872168336346)\">in</mark> <mark style=\"background-color:rgba(0,255,0,0.25508833268782644)\">relay</mark> <mark style=\"background-color:rgba(255,0,0,0.3044964196413428)\">duel</mark> <mark style=\"background-color:rgba(0,255,0,0.6602790277556422)\">against</mark> <mark style=\"background-color:rgba(0,255,0,0.42291164970169626)\">australia</mark> <mark style=\"background-color:rgba(0,255,0,0.22247338474801304)\">thens</mark> <mark style=\"background-color:rgba(255,0,0,0.16259022236874066)\">,</mark> <mark style=\"background-color:rgba(255,0,0,0.2223194531453649)\">aug</mark> <mark style=\"background-color:rgba(255,0,0,0.3007579113183533)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.2318130156333523)\">17</mark> <mark style=\"background-color:rgba(255,0,0,0.16407394825092783)\">-</mark> <mark style=\"background-color:rgba(0,255,0,0.33224275379797386)\">so</mark> <mark style=\"background-color:rgba(0,255,0,0.27860320072690986)\">michael</mark> <mark style=\"background-color:rgba(0,255,0,0.37531557030999674)\">phelps</mark> <mark style=\"background-color:rgba(255,0,0,0.4604766493498543)\">is</mark> <mark style=\"background-color:rgba(0,255,0,0.524198045098917)\">not</mark> <mark style=\"background-color:rgba(0,255,0,0.3621860595431242)\">going</mark> <mark style=\"background-color:rgba(255,0,0,0.3182210706575793)\">to</mark> <mark style=\"background-color:rgba(0,255,0,0.6230259918704261)\">match</mark> <mark style=\"background-color:rgba(0,255,0,0.5492536390429353)\">the</mark> <mark style=\"background-color:rgba(0,255,0,0.11699513076224131)\">seven</mark> <mark style=\"background-color:rgba(0,255,0,0.688458424946987)\">gold</mark> <mark style=\"background-color:rgba(0,255,0,0.4768935942922794)\">medals</mark> <mark style=\"background-color:rgba(0,255,0,0.603559347805522)\">won</mark> <mark style=\"background-color:rgba(255,0,0,0.6276476610006153)\">by</mark> <mark style=\"background-color:rgba(0,255,0,0.42488668540454444)\">mark</mark> <mark style=\"background-color:rgba(255,0,0,0.2495174584447216)\">spitz</mark> <mark style=\"background-color:rgba(255,0,0,0.3007579113183533)\">.</mark> <mark style=\"background-color:rgba(255,0,0,0.3915520726608193)\">and</mark> <mark style=\"background-color:rgba(255,0,0,0.40574734325918826)\">it</mark> <mark style=\"background-color:rgba(255,0,0,0.4604766493498543)\">is</mark> <mark style=\"background-color:rgba(0,255,0,0.4007662201067789)\">too</mark> <mark style=\"background-color:rgba(255,0,0,0.16370083961842824)\">early</mark> <mark style=\"background-color:rgba(255,0,0,0.3182210706575793)\">to</mark> <mark style=\"background-color:rgba(0,255,0,0.16690985081882923)\">tell</mark> <mark style=\"background-color:rgba(0,255,0,0.3262000770931649)\">if</mark> <mark style=\"background-color:rgba(0,255,0,0.9734095534737479)\">he</mark> <mark style=\"background-color:rgba(0,255,0,0.2929088706932789)\">will</mark> <mark style=\"background-color:rgba(0,255,0,0.6230259918704261)\">match</mark> <mark style=\"background-color:rgba(255,0,0,0.20520636773726958)\">aleksandr</mark> <mark style=\"background-color:rgba(255,0,0,0.09931701868982784)\">dityatin</mark> <mark style=\"background-color:rgba(255,0,0,0.16259022236874066)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.5492536390429353)\">the</mark> <mark style=\"background-color:rgba(0,255,0,0.08771756872144876)\">soviet</mark> <mark style=\"background-color:rgba(255,0,0,0.08602951286183767)\">gymnast</mark> <mark style=\"background-color:rgba(0,255,0,0.2617592694536051)\">who</mark> <mark style=\"background-color:rgba(0,255,0,0.603559347805522)\">won</mark> <mark style=\"background-color:rgba(0,255,0,0.2469768049400703)\">eight</mark> <mark style=\"background-color:rgba(0,255,0,0.287465351491189)\">total</mark> <mark style=\"background-color:rgba(0,255,0,0.4768935942922794)\">medals</mark> <mark style=\"background-color:rgba(255,0,0,0.31660872168336346)\">in</mark> <mark style=\"background-color:rgba(255,0,0,0.22638705614951454)\">1980</mark> <mark style=\"background-color:rgba(255,0,0,0.3007579113183533)\">.</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_text_attr(attrs_ig[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9ca1a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrs_ig_corr = attrs_ig[0]\n",
    "# attribution_shap_corr = attribution_shap[0]\n",
    "# attribution_lime_corr = attrs_laso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07ee6d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Smooth Grad\n",
    "# TODO : Adversarial Methods\n",
    "# TODO : Some more for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "335e0515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "corr_matrix = np.zeros([pointer, pointer])\n",
    "for col_a, col_b in itertools.combinations_with_replacement(range(pointer), 2):\n",
    "    corr_matrix[col_a][col_b], _ = pearsonr(EXPLANATIONS[col_a], EXPLANATIONS[col_b])\n",
    "    corr_matrix[col_b][col_a] = corr_matrix[col_a][col_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6e96bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(index = None, column = None, data = None, plot_path = None):\n",
    "    import seaborn as sn\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    # array = [[33, 2, 0, 0, 0, 0, 0, 0, 0, 1, 3],\n",
    "    #          [3, 31, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    #          [0, 4, 41, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "    #          [0, 1, 0, 30, 0, 6, 0, 0, 0, 0, 1],\n",
    "    #          [0, 0, 0, 0, 38, 10, 0, 0, 0, 0, 0],\n",
    "    #          [0, 0, 0, 3, 1, 39, 0, 0, 0, 0, 4],\n",
    "    #          [0, 2, 2, 0, 4, 1, 31, 0, 0, 0, 2],\n",
    "    #          [0, 1, 0, 0, 0, 0, 0, 36, 0, 2, 0],\n",
    "    #          [0, 0, 0, 0, 0, 0, 1, 5, 37, 5, 1],\n",
    "    #          [3, 0, 0, 0, 0, 0, 0, 0, 0, 39, 0],\n",
    "    #          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 38]]\n",
    "    df_cm = pd.DataFrame(data, index=index,\n",
    "                         columns=column)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sn.heatmap(df_cm) # annot=True)\n",
    "    plt.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21918f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(index = EXPLANATION_NAMES.keys(), column = EXPLANATION_NAMES.keys(), data = corr_matrix, plot_path = \"three.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d29a9962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9defd140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
